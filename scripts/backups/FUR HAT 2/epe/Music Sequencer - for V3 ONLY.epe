{
  "name": "Music Sequencer - for V3 ONLY",
  "id": "CjQMFsk8qPgNurZRb",
  "sources": {
    "main": "/*\n  Music Sequencer is a pattern that makes it easier to choreograph LEDs to\n  songs that have steady tempos. It includes basic tempo detection for 4/4 \n  beats and many helpers for making patterns more sound reactive.\n  \n  This version requires a sensor board and contains many example patterns.\n  \n    Demo: https://youtu.be/IjhYH3B7EI8\n  \n  Your sub-patterns can consume a variety of helpful duration timers.\n  `currentPatternPct` and `phrasePct' ramp up like time(). `wholenote`, \n  `halfnote`, `beat`, `note_8', and `note_16` ramp down, from 1 -> 0.\n  \n  To use the sequencer, create a pattern sequence at the end of all other code.\n  Do this by entering a series of `enqueue(beforeRenderer(), beatCount)`\n  statements. Each beforeRenderer() function must set a renderer.\n  \n  A basic sequence might look like this:\n    \n    function party(delta) { renderer = (i) => <hsv() and stuff> }\n    function stars(delta) { <beforeRenderStuff>; renderer = (i) => <hsv() and stuff> }\n  \n    setBPM(125)               // Set a manual tempo. `BPM = 125`\n    setBeatsPerPhrase(16)     // Patterns can be phrase-aware\n    enqueue(stars)            // 'stars' pattern for an entire phrase (16 beats)\n    enqueue(party, 8)         // 8 beats of a pattern named 'party'\n    enqueue(off, 4)           // All LEDs off for 4 beats\n    exec(() => hue = .3)      // Instantly set global variable named hue\n    enqueue(patternThatUsesHue)\n    playUntilBeat(off, 16)    // Wait up to 16 beats with no LEDs on; start the\n                              // next pattern in queue once a beat is detected.\n    enqueue(stars)            // `stars` plays on-beat\n                              // Now, sometime in the background, >=8 beats of a\n                              // 4/4 tempo have been detected at 124 BPM.\n    setBPMToDetected()        // Sets `BPM = 124`\n    q(party)                  // q is shorthand for enqueue. Plays at 124 BPM.\n    begin()                   // Required at the very end to start things.\n  \n  Tempo detection and frequency domain effects require the Pixelblaze sensor \n  expansion board. Sound paramaters have been tuned for use with the sensor \n  board's 3.5mm line-in jack. Results using the built-in mic will vary greatly\n  by proximity and loudness. Visual params are set for SK9822 LEDs at \n  25%-of-max brightness.\n  \n  A note on the style: This pattern is a bit of an abuse of Pixelblaze.\n  With all the demo patterns, it's well over 1200 lines. You may wish to\n  start by folding all code sections, which is Alt-0 on Windows and \n  Command-Option-0 on Mac. Also, clarity has been sacrificed. Demo renderers\n  are dense, preferencing fewer lines.\n\n  Jeff Vyduna, 2021. MIT License.\n*/\n\n\n// IMPORTANT WARNING!!! PLEASE READ\n/*\n  This pattern was developed for Pixelblaze v3. Pixelblaze v3 can have\n  up to 256 globals variables or functions. With the provided demo\n  patterns, there's about 250 globals in use! Adding too many more \n  functions or variables will crash the board on firmware v3.18 and\n  prior. v3.18 is the most recent v3 firmawre as of 9/6/21. It *will*\n  crash if you add much more code to this pattern. Instead, start by \n  removing patterns, variables and functions you aren't using. For \n  example, if you aren't using an external sensor board, you can comment \n  out all `process<Sound>` functions and their preceeding vars to get\n  back many globals for your use.\n  \n  Pixelblaze v2 can have up to 128 globals variables or functions, and\n  will also crash above this as of the current version, v2.27. That \n  means that this pattern you're reading is DEFAULT-UNSAFE right now \n  for Pixelblaxe version 2 boards. In the pattern library, you can find \n  \"Music Sequencer for v2\" instead, which uses about 125 globals.\n  \n  With repeated crashes, boards can become difficult to recover - they \n  will try restarting with a previous pattern, then with no LED config, \n  and finally with no WiFi config. Please proceed with caution, and remove\n  code for patterns you do not use before adding more code. I have bricked\n  a Pixelblaze by getting into a state where crashing code is running \n  behind an unresponsive WiFi config. Recovery requires an additional \n  board and an involved reflashing procedure.\n*/\n\n\n\n// Values that come from the Sensor Board\nexport var light = -1 // If this remains at the impossible value of -1, a sensor board is not connected.\nfunction SB() { return light != -1 }\nexport var frequencyData = array(32)\nexport var energyAverage, maxFrequency, maxFrequencyMagnitude\n\n\nexport function beforeRender(delta) {\n  if(SB()) processSound(delta)\n  updateTimers(delta)\n  currentBeforeRenderer(delta)\n}\n\nexport function render(index) { render3D(index, index / pixelCount, 0, 0) }\nexport function render2D(index, x, y) { render3D(index, x, y, 0) }\nexport function render3D(index, x, y, z) {\n  // `renderer()` will be reassigned by your patterns (every beforeRenderer)\n  renderer(index, x, y, z);\n}\n\n\n\n// ************************************************************************\n// * SOUND, BEAT AND TEMPO DETECTION                                      *\n// ************************************************************************\n\n\nfunction processSound(delta) {\n  processVolume(delta)\n  processInstruments(delta)\n  inferTempo(delta)\n}\n\n\n// Volume normalization. EA = EnergyAverage, EMA = Exponential Moving Average\nvar EAThreshold = .02, maxEA = EAThreshold * 1.1, smoothedEA = EAThreshold, maxEATimer\nexport var localVolRatio = .5 // Ratio of instantaneous volume to recent average volume. Useful in pattern code.\nexport var volume = .25       // Volume 0..1. 0 = below EAThreshold, 1 = loudest heard in 80 seconds (accum in maxEATimer)\n\nfunction processVolume(delta) {\n  // EMA = k * thisSample + (1-k) * EMA; k = 2/(samples + 1); k=.02 -> 99 samples, 2.5 sec\n  //                                                          k=.05 -> 40 samples, 1 sec\n  // 120bpm 1B=.5s, 40hz = 20 samples minimum to span 4:4 beats\n  var scaledEA = energyAverage << 4 // The empirical max I observed * 16 results in energyAverage scaled to roughly 1.5 for line-in, bass-heavy; .8-.9 typical for loud music on line in, or .6 for loud laptop right next to SB mic. \n  smoothedEA = .05 * scaledEA + .95 * smoothedEA // Exp Avg\n  if (scaledEA >= maxEA) { maxEA = scaledEA; maxEATimer = 0 } // Max volume found. Reset timer.\n  maxEATimer += delta / 10 //  Accumulate time since we've seen a max volume reading. 1 = 10ms.\n  if (scaledEA > EAThreshold && maxEATimer >= 8000) maxEA *= .99 // Conservatively long period before reducing the loudest volume possible. Longer than any bridge. 80s ~= 5 phrases @120BPM.\n  maxEATimer = min(8000, maxEATimer)\n  \n  // Compare to a silence threshold; if it's above silence, return a nonzero ratio. E.g. `if (localVolRatio > 1.5) burst()`. Fast moving (40Hz, same as sensor board)\n  localVolRatio = scaledEA > EAThreshold && scaledEA / smoothedEA\n  volume = scaledEA > EAThreshold && smoothedEA / maxEA //  Smoothed volume 0..1; 1 = loudest heard in the last 80 seconds\n  \n  // You can queue something that skips to the next one when volume spikes. If detected, start the next pattern and skip some ms in to correct for the estimated time it took to detect this volume spike.\n  if (continueMode == 2 && volume > .8) next(40)\n}\n\n// Debounced detectors\n{  // Brackets are used at times to enable code folding in the editor.\nvar minBeatRetrigger = .2 // How much of a currently defined quarter note beat must pass before a detected instrument will retrigger? E.g. use .2 to allow .25 retrigger (e.g. to catch sixteenth note drums)\nvar beatTimerIdx = 0, clapsTimerIdx = 1, hhTimerIdx = 2\nvar debounceTimers = array(3)\nvar beatsToMs = (_beats) => 1000 / BPM * 60 * _beats\ndebounceTimers.mutate(() => beatsToMs(minBeatRetrigger))\n}\nfunction debounce(trigger, fn, timerIdx, duration, elapsed) {\n  if (trigger && debounceTimers[timerIdx] <= 0) { \n    fn()\n    debounceTimers[timerIdx] = duration\n  } else { \n    debounceTimers[timerIdx] = max(-3e4, debounceTimers[timerIdx] - elapsed)\n  }\n}\n\nvar hh, hhEMA = .1, hhOn     // High hat. Frequencies ~ 9KHz\nvar claps, clapsEMA = .1, clapsOn  // Claps frequencies\nvar bass, maxBass, bassOn    // Bass and beats\nvar bassSlowEMA = .001, bassFastEMA = .001 // Exponential moving averages to compare to each other\nvar bassThreshold = .02      // Raise this if very soft music with no beats is still triggering the beat detector\nvar maxBass = bassThreshold  // Maximum bass detected recently (while any bass above threshold was present)\n\n// Redefine these in your patterns to do something that reacts to these instruments\nfunction beatDetected() {}\nfunction clapsDetected() {}\nfunction hhDetected() {}\n\nvar hhThreshold = 2\n// Uncomment to tune the high hat detection threshold\n// export function sliderHighhatThreshold(_v) { hhThreshold = _v * 4 }\nfunction processInstruments(delta) {\n  hh = (frequencyData[29] + frequencyData[30]) << 4 // Readings in these bins are typically so low that *16 gives the EMA more headroom\n  hhOn = hh > hhThreshold * hhEMA // hhOn, clapsOn, and bassOn can be true for multiple frames, unlike hhDetected(), clapsDetected(), beatDetected(), which will be debounced and called only once per event.\n  debounce(hhOn, hhDetected, hhTimerIdx, beatsToMs(minBeatRetrigger), delta)\n  hhEMA = .02 * hh + .98 * hhEMA\n  \n  claps = 0; for (i = 18; i <= 24; i++) claps += frequencyData[i] << 4\n  clapsOn = claps > 3 * clapsEMA\n  debounce(clapsOn, clapsDetected, clapsTimerIdx, beatsToMs(minBeatRetrigger), delta)\n  clapsEMA = .02 * claps + .98 * clapsEMA\n\n  // Assume Sensor Board updates at 40Hz (25ms); Max BPM 180 = 333ms or 13 samples; Typical BPM 500ms, 20 samples\n  // Kickdrum fundamental 40-80Hz. https://www.bhencke.com/pixelblaze-sensor-expansion\n  bass = frequencyData[1] + frequencyData[2] + frequencyData[3]\n  maxBass = max(maxBass, bass)\n  if (maxBass > 10 * bassSlowEMA && maxBass > bassThreshold) maxBass *= .99 // AGC - Auto gain control\n  \n  bassSlowEMA = (bassSlowEMA * 999 + bass) / 1000\n  bassFastEMA = (bassFastEMA * 9 + bass) / 10\n}\n\n\n\nvar bassVelocitiesSize = 5 // 5 seems right for most. Up to 15 for infrequent bass beats (slower reaction, longer decay), down to 2 for very fast triggering on doubled kicks like in drum n bass\nvar bassVelocities = array(bassVelocitiesSize) // Circular buffer to store the last 5 first derivatives of the `fast exponential avg/MaxSample`, used to calculate a running average\nvar lastBassFastEMA = .5, bassVelocitiesAvg = .5\nvar bassVelocitiesPointer = 0 // Pointer for circular buffer\n\n// Store the last 8 intervals between beats. Longest = 50BPM on beat 1 (4800 ms = 60 / 50BPM * 1000 * 4)\nvar beatIntervalSamples = 8, beatIntervalPtr = 0, beatIntervalTimer = 0\nvar beatIntervals = array(beatIntervalSamples)\n\nfunction inferTempo(delta) {\n  bassVelocities[bassVelocitiesPointer] = (bassFastEMA - lastBassFastEMA) / maxBass // Normalized first derivative of fast moving expo avg\n  bassVelocitiesAvg += bassVelocities[bassVelocitiesPointer] / bassVelocitiesSize\n  bassVelocitiesPointer = (bassVelocitiesPointer + 1) % bassVelocitiesSize\n  bassVelocitiesAvg -= bassVelocities[bassVelocitiesPointer] / bassVelocitiesSize\n  bassOn = bassVelocitiesAvg > .51 // `bassOn` is true when bass is rising\n  \n  debounce(bassOn, beatDetectedWrapper, beatTimerIdx, beatsToMs(minBeatRetrigger), delta)\n  beatIntervalTimer += delta\n  // Longest = 50BPM on beat 1 (4800 ms = 60 / 50BPM * 1000 * 4)\n  if (beatIntervalTimer > 5000) beatIntervalTimer = 5000 // No-beat ms threshold to reset beat detection \n  \n  lastBassFastEMA = bassFastEMA\n}\n\nfunction beatDetectedWrapper() {\n  if (beatIntervalTimer >= 5000) { // Clear beat intervals, it's been too long since a beat\n    beatIntervals.mutate(() => 0)\n    beatIntervalTimer = beatIntervalPtr = 0\n  }\n  beatIntervals[beatIntervalPtr] = beatIntervalTimer\n  beatIntervalTimer = 0\n  beatIntervalPtr = (beatIntervalPtr + 1) % beatIntervalSamples\n  if (beatIntervals[0] != 0) estimateBPM() // We have all 8 beatIntervalSamples, so estimate tempo\n\n  // You can queue a pattern that skips to the next one when when a beat drops. If a beat dropped, start the next pattern and skip 50-250ms (depending on beat detection settings) in to correct for the estimated time it took to detect this beat.\n  if (continueMode == 1) next(120)\n\n  beatDetected() // Calls a function that can be user-defined in patterns\n}\n\n\n\nexport var BPMEst = 0, BPMEstReliable = 0 // Last successfully estimated tempo, and a boolean for whether it is currently thought to still be ccurate\nvar meanBeatInterval = 0 // Global just so it can be used in arrayReduce() below\nfunction estimateBPM() {\n  meanBeatInterval = beatIntervals.sum() / beatIntervalSamples\n  \n  var errSum = beatIntervals.reduce((a, v) => {\n    var diff = (v - meanBeatInterval) / 100 // Range precision: scale the samples down by /= 100 before summation\n    return a + diff * diff\n  }, 0)\n  \n  var stdDev = sqrt(errSum / beatIntervalSamples) / (meanBeatInterval / 100)\n  if (stdDev < .1) { \n    BPMEst = 6000 / (meanBeatInterval / 10)  // 60,000 ms in a minute. Done this way to prevent overflow.\n    BPMEst = round(BPMEst) // Optional - Most non-live music is released with integer BPM tempo. If syncing to live performance / turntable DJs, comment this out.\n    BPMEstReliable = 1\n  } else {\n    BPMEstReliable = 0\n  }\n}\n\n\n\n\n\n\n// ************************************************************************\n// * PATTERN AND COMMAND QUEUE                                            *\n// ************************************************************************\n\n\nexport var BPM = 120        // Nominal BPM. Can be set mid-sequence with setBPM(bpm) or setBPMToDetected()\nvar SPB                     // Inferred \"seconds per beat\" from BPM\nvar beatsPerMeasure = 4\nvar beatsPerPhrase = 32     // A phrase is the default duration in beats when `enqueue(pattern)` is called with no second argunment for duration.\nvar currentPatternMs = 0    // ms into the current pattern, wrapped back to 0 after 32000 ms\nvar currentPatternS = 0     // Seconds into the current pattern\nvar currentPatternDuration = 0  // Current pattern's total duration, in seconds\nvar currentPatternBeats = 0     // Current pattern's total duration, in beats\nvar currentPatternPct = 0       // 0..1 like time(), this is the percentage of the current pattern that has run\nvar beatCount                   // Number of beats into the current pattern, as an increasing decimal counter\nvar phrasePct                   // Percent into the current phrase, as defined by beatsPerPhrase\n\n// Percent remaining in wholenote, halfnote, beat (quarternote), 8th, 16th, and measure (as defined by `beatsPerMeasure`)\n// These go from 1 to 0 and jump back suddently to 1 on the next interval, I.E., they have the opposite ramp as `time()`, `currentPatternPct`, and `phrasePct`\nvar measure, wholenote, halfnote, beat, note_8, note_16 \nvar currentBeforeRenderer       // A reference to the current pattern's beforeRender() equivalent. This is always called in beforeRender, and it should set `renderer` to a function like render3d(i, x, y, z)\nvar totalPatternCount = 0       // `enqueue()` increments this as patterns are added to the queue\nvar currentPatternIdx = 0             // Main index for the queue (which pattern is currently playing).\nvar beforeRendererQueue = array(256)  // This is the main pattern queue, storing beforeRenderers()\nvar durationQueue = array(256)        // Stores the duration for each corresponding pattern in beforeRendererQueue, in units of beats. Otherwise, for commands (immediate single execution), the entry is an argument passed to the function.\nvar continueModeQueue = array(256)    // Modality for when to proceed to the next entry in the queue\nvar continueMode                      // 0: Continue after a specified duration.  1: After beat detected or the duration.  2: After volume spikes or the duration.  9: Execute once immediately and proceed.\n\n\n// enqueue(BRFn) - Add an action (a pattern, delay, or command) to the queue. Aliased as `q(BRFn)`.\n/*\n  BRFn: A beforeRender(delta) function. It should assign a `renderer = (index, x, y, z) => {}`\n        If continueMode == 9, this is a command function that will be executed once, after which the queue proceeds\n\n  _beats: The duration this renderer will execute for, in beats at the current BPM\n          If continueMode == 1 or 2, the pattern may plan for less time if an audio condition is detected from an attached sensor board\n          if continueMode == 9, this value will be passed as an argument to the command function\n\n  continueMode: 0 - Proceed to the next pattern or command in the queue once the duration has expired\n                1 - Like 0, but if a bass pulse is detected, then proceed to the next pattern early\n                2 - Like 0, but if a volume spike is detected, such as from silence to any sound, then proceed to the next pattern early\n                3-8 - Reserved for future use\n                9 - Execute BrFn() once immediately with _beats passed as an argument, then proceed\n                Anything else - expect a function reference. Execute the function and proceed if it evaluates truthy.\n*/\n\nfunction enqueue(BRFn, _beats, continueMode) {\n  beforeRendererQueue[totalPatternCount] = BRFn\n  durationQueue[totalPatternCount] = _beats\n  continueModeQueue[totalPatternCount] = continueMode\n  totalPatternCount++\n}\nq = enqueue     // Shorthand you'll appreciate when using this a lot\n\n// Queue a pattern that will be played until either the duration expires, or a beat is detected\nfunction playUntilBeat(BRFn, _beats) {\n  enqueue(BRFn, _beats, 1)\n}\n\n// Queue a pattern that will be played until either the duration expires, or the volume spikes\nfunction playUntilLoud(BRFn, _beats) {\n  enqueue(BRFn, _beats, 2)\n}\n\n// These are \"commands\" in that they may a change to a global like the BPM tempo, but execute once instantly instead of for a specified duration.\n\n// Shorthand to enqueue the one-time execution of a function at that point in the queue\nfunction exec(fn, argument) {\n  if (argument == 0) {\n    enqueue(fn, null, 9)\n  } else {\n    enqueue(fn, argument, 9)\n  }\n}\n\n// Note: setBPM(<30) screws up beat detection, missing beats. It's complicated why, and isn't worth refactoring for.\nfunction setBPM(_bpm) {\n  enqueue((__bpm) => BPM = __bpm, _bpm, 9)\n}\n\nfunction setBPMToDetected() {\n  enqueue((_) => BPM = BPMEst || BPM, null, 9)  // Keep the previously specified BPM if none is detected\n}\n\nfunction setBeatsPerPhrase(_bpp) {\n  enqueue((__bpp) => beatsPerPhrase = __bpp, _bpp, 9)\n}\n\n// This can be used as a command in queue to calibrate for bass when there hasn't been time to baseline the various autmatic gain controls. Helps initial beat detection. Set higher for inputs with high volume, such as full line-in.\nfunction expectBass(bassLvl) {\n  exec((_bassLvl) => { maxBass = _bassLvl; bassSlowEMA = maxBass / 2 }, bassLvl)\n}\n\n// updateTimers() is called in beforeRender(). Updates timers that patterns can use, like \n// `beat` (% of beat remaing), etc. Also determines when a pattern is complete and it's \n// time to go to the next thing in the queue.\nvar ONE_MINUS_EPSILON = (0xFF >> 16) + (0xFF >> 8) // One minus the smallest number. Highest result of `x % 1`.\n\nfunction updateTimers(delta) {\n  currentPatternMs += delta\n  if (currentPatternMs > 32000) { currentPatternMs -= 32000 }\n  currentPatternS += delta / 1000\n  if (currentPatternS >= currentPatternDuration) next()\n  currentPatternPct = currentPatternS / currentPatternDuration\n\n  SPB = 60 / BPM  // Seconds per beat\n  beatCount = currentPatternS / SPB\n  phrasePct = currentPatternS / (beatsPerPhrase * SPB) % 1\n  measure = ONE_MINUS_EPSILON - currentPatternS / (beatsPerMeasure * SPB) % 1\n  wholenote = ONE_MINUS_EPSILON - currentPatternS / (4 * SPB) % 1\n  halfnote = 2 * wholenote % 1\n  beat = 4 * wholenote % 1\n  note_8 = 8 * wholenote % 1\n  note_16 = 16 * wholenote % 1\n}\n\n// Code to run once between patterns to reset shared state\nfunction beforeNext() {\n  // Clear shared variables\n  for (i = 0; i < pixelCount + 1; i++) {\n    hArr[i] = 0; sArr[i] = 1; vArr[i] = 0\n  }\n  setupDone = 0    // Allow any setup block defined to execute once\n  lastTrigger = -1 // Clear the rising/falling edge trigger\n  beatDetected = clapsDetected = hhDetected = () => {}  // Unassign any instrument-reactive functions\n}\n\n// Start the next pattern in the queue, beginning `startAtMs` milliseconds into it (usually 0)\nfunction next(startAtMs) {\n  beforeNext()\n  \n  currentPatternMs = startAtMs\n  currentPatternS = currentPatternMs / 1000\n  currentPatternIdx++\n  \n  if (currentPatternIdx >= totalPatternCount) {\n    loop() // Specify your desired ending behavior here -- loop(), halt(), or repeatLast()\n    return\n  }\n  \n  currentPatternBeats = durationQueue[currentPatternIdx]\n  continueMode = continueModeQueue[currentPatternIdx]\n  \n  if (continueMode <= 2) { // Run pattern for specified duration (0) or until beat detected (1) or until volume spikes (2)\n    currentBeforeRenderer = beforeRendererQueue[currentPatternIdx]\n    currentPatternBeats = currentPatternBeats || beatsPerPhrase\n    currentPatternDuration = currentPatternBeats * 60 / BPM\n  } else if (continueMode == 9) { // Run function once with an argument\n    beforeRendererQueue[currentPatternIdx](currentPatternBeats) \n    next()\n  } else if (continueMode()) { next() } // Otherwise expect a function that will evaluate truthy to proceed\n}\n\nfunction halt() { beforeRender = (d) => { renderer = (i,x,y,z) => { hsv(0,0,0) } } }\nfunction loop() { begin() }\nfunction repeatLast () { currentPatternIdx-- }\n\nfunction begin() { // This must appear at the very end of the sequence / queue definition, usually the last line of the entire pattern\n  currentPatternIdx = -1\n  next()\n}\n\n\n\n\n\n\n\n// ************************************************************************\n// * YOUR PATTERNS                                                        *\n// ************************************************************************\n\n\n//  SHARED VARIABLES that multiple patterns might use\n\nvar setupDone = 0 // Use to run something once for setup. `if (!setupDone) { a = 0; setupDone = 1 }`\n\nvar hArr = array(pixelCount + 1) // An extra value avoids index errors in interpolation loops\nvar sArr = array(pixelCount + 1)\nvar vArr = array(pixelCount + 1)\n\nvar themeHue     // A theme hue that multiple patterns can consume\nvar direction    // If a pattern can be reversed, it can read this global variable to determine direction\n\n// PI Controller for automtic gain control\nvar targetFill = 0.2         // Set this in your pattern\nvar brightnessFeedback = 0   // Accumulates final v values from output\nvar sensitivity = 0          // The calculated gain to reduce error against the goal\nvar pic = makePIController(.25, .15, 20, 0, 1000)\n\nfunction makePIController(kp, ki, start, min, max) {\n  var pic = array(5)\n  pic[0] = kp; pic[1] = ki; pic[2] = start; pic[3] = min; pic[4] = max\n  return pic\n}\n\nfunction calcPIController(pic, err) {\n  pic[2] = clamp(pic[2] + err, pic[3], pic[4])\n  return max(pic[0] * err + pic[1] * pic[2], 0)\n}\n\n\n\n// HELPERS - Code that multiple patterns might use\n\n// Return a more perceptually rainbow-ish hue\nfunction fixH(pH) {\n  return wave((mod(pH, 1) - .5) / 2)\n}\n\n// Returns 1 when a & b are proximate, 0 when they are more than `halfwidth`\n// apart, and a gamma-corrected brightness for distances within `halfwidth`\nfunction near(a, b, halfwidth) {\n  if (halfwidth == 0) halfwidth = .125\n  var v = clamp(1 - abs(a - b) / halfwidth, 0, 1)\n  return v * v\n}\n\n// Returns an integer where A4 (440Hz) is 12. (C4 is middle C, 3). For a sine wave,\n// semitones above C5 (return value of 15) are reliably distinguishable.\n// So - you know, flute solo.\nvar noteNum\nfunction detectNote() {\n  return round(12 * log2(maxFrequency / 220))\n}\n\n// Reduce all vArr[] exponentially, where 1.0 decays to 0.0001 in ~`seconds`\nfunction decay(seconds, delta) {\n  delta = delta || 3 // Test result: delta is 3 ms for 320FPS on v3 with 128 LEDs\n  var decayCoeff = pow(2, log2(.99) * delta / seconds / 2)\n  for (i = 0; i < vArr.length; i++) vArr[i] *= decayCoeff\n}\n\n// Execute fn once upon detection of a rising (default) or falling edge\nvar lastTrigger = -1\nfunction triggerOn(t, fn, onFalling) {\n  if (lastTrigger == -1) lastTrigger = onFalling\n  if (lastTrigger != t && (onFalling ^ t > lastTrigger)) fn()\n  lastTrigger = t \n}\n\n// Various blending modes\nvar mixedH, mixedV\n// Add two hue, value vectors assuming full saturation. \n// https://math.stackexchange.com/questions/1365622/adding-two-polar-vectors\n// This is slightly faster than doing it via cartesian conversion\nfunction mixHV(h1, v1, h2, v2) { \n  v1 = clamp(v1, 0, 1); v2 = clamp(v2, 0, 1)\n  var cosHues = v2 * cos((h2 - h1) * PI2)\n  mixedV = sqrt(v1 * v1 + v2 * v2 + 2 * v1 * cosHues)\n  mixedH = h1 + atan2(v2 * sin((h2 - h1) * PI2), v1 + cosHues) / PI2\n}\n\n\n\n// RENDERERS\n\n// For the demo version of this pattern, these are very dense to reduce LOC. Sorry.\n\nfunction off(delta) { renderer = (i, x, y, z) => hsv(0, 0, 0) }\n\n\n// Red progress meter for the duration it's enqueued for, but also pulses to quarter notes\nfunction progress(delta) {\n  renderer = (i, x, y, z) => {\n    var pct = direction > 0 ? i / pixelCount : 1 - i / pixelCount\n    hsv(themeHue, 1, beat * (currentPatternPct > pct))\n  }\n}\n\n\n// Progress meter for one measure\nfunction measureProgress(delta) {\n  renderer = (i, x, y, z) => {\n    var pct = direction > 0 ? i / pixelCount : 1 - i / pixelCount\n    hsv(themeHue, 1, beat * (measure > pct))\n  }\n}\n\n\n// Sweep a pulse across the strip to the beat\nfunction sweep(delta) { \n  renderer = (i, x, y, z) => {\n    var pct = direction > 0 ? i / pixelCount : 1 - i / pixelCount\n    hsv(themeHue, 1, near(pct, beat))\n  }\n}\n\n\nfunction quarters(delta) {\n  renderer = (i, x, y, z) => { hsv(themeHue - .02 * triangle(i / pixelCount), 1, beat * triangle(i / pixelCount)) }\n}\n\n\nfunction eiths(delta) { \n  renderer = function(i, x, y, z) { \n    var positionEith = floor(8 * i / pixelCount)\n    var measureEith = floor(8 * measure)\n    var v = (positionEith == measureEith) * note_8\n    hsv(.05 + themeHue - measure / 10, sqrt(sqrt(3 * measure - 1)), v * v)\n  }\n}\n\nvar flash\nfunction strobe() {\n  flash = note_16 > .8\n  renderer = (index, x, y, z) => { hsv(0, 0, flash) }\n}\n\n\n// Colors eminante from the center and withdraw quickly every 2 beats\nvar halfnoteEMA = 0\nfunction halfSurge(delta) {\n  halfnoteEMA = .9 * halfnoteEMA + .1 * halfnote\n  renderer = (index, x, y, z) => { \n    var pct = 3 * (index / pixelCount - .5)\n    var v = abs((phrasePct - sqrt(currentPatternPct) * halfnoteEMA / 5) * 4 / sqrt(pct) % 1)\n    hsv(fixH(v / (4 - 3 * currentPatternPct) - .6), 1, v * v * triangle(index / pixelCount))\n  }\n}\n\n\nvar pos\nfunction dancingPixel(delta) { \n  var s8 = square(note_8, .25) / 15\n  var w444 = wave(beat) * wave(beat) * wave(beat) / 8\n  var cWP = .1 + .8 * wave(currentPatternPct)\n  var sqJitter = s8 * (1 - currentPatternPct)\n  var bassDance = currentPatternPct * currentPatternPct * (bassFastEMA / maxBass) / 4\n  pos = cWP + currentPatternPct * w444 + sqJitter + bassDance\n  renderer = renderDancingPixel\n}\nfunction renderDancingPixel(i, x, y, z) {\n  var width = bassFastEMA / maxBass / 2 * square(currentPatternPct - .5, .125)\n  var v = near(pos, i / pixelCount, width)\n  hsv(fixH(themeHue - .53 * (currentPatternPct > .5) ), 1, v * v) \n}\n\n\n// Fake bass 1D oscilliscope - 2 beats\nfunction halfnoteBassHit(delta) {\n  var bassDFreq = .6 * wave((5 + 5 * halfnote) * halfnote) - .3\n  pos = .5 + bassDFreq * pow(halfnote, 3) // Bassdrum freq * amplitude decay\n  baseH = .15 * (1 - currentPatternPct)\n  \n  renderer = (i, x, y, z) => {\n    v = near(pos, i / pixelCount)\n    hsv(fixH(baseH - v / 8), 1, v * v)\n  }\n}\n\n\n// Fake bass 1D oscilliscope\nfunction bassScope() { \n  var bassDFreq = .6 * wave((10 + 20 * beat) * beat) - .3\n  pos = .5 + bassDFreq * pow(beat, 3) // Bassdrum freq * amplitude decay\n  width = triangle(currentPatternPct)\n  width = .05 + width * width * width\n  baseH = 1 - currentPatternPct * floor(measure * beatsPerMeasure) / beatsPerMeasure\n  renderer = (i, x, y, z) => {\n    v = near(pos, i / pixelCount, width)\n    hsv(fixH(baseH - v / 6), 1, v * v)\n  }\n}\n\n\n// Paint Fizzle: 1D Texture brush. Best in hip hop / uneven beats.\nvar paintPtr, paintStart, paintLen, paintArrPtr, paintHue\nfunction paintFizzle(newFizzle) {\n  var paintMinLen = pixelCount/10\n  if (newFizzle) {  // || abs(paintPtr - paintStart) >= abs(paintLen)) { // Uncomment the remainder for use with songs that don't have beats (and consider reducing paintMinLen)\n    paintHue = time(10 / 65.536) + (random(1) > .5 ? 0 : .15)\n    paintPtr = paintArrPtr = paintStart = mod(paintStart + 2 * paintMinLen + random(pixelCount - 3 * paintMinLen), pixelCount)\n    paintLen = (paintMinLen + random(pixelCount - paintMinLen)) * (random(1) > .125 ? paintLen/paintLen : -paintLen/paintLen) // Signed direction. Baysean.\n    vArr[paintStart] = random(1); hArr[paintStart] = fixH(paintHue)\n  }\n\n  for (i = 0; i <= newFizzle * paintMinLen; i++) { // Do once, unless newFizzle\n    paintLen > 0 ? paintPtr++ : paintPtr--\n    prevPtr = paintArrPtr\n    var paintArrPtr = mod(paintPtr, pixelCount)\n    vArr[paintArrPtr] = .1 + random(.2)\n    if (vArr[prevPtr] > .5 ^ .8 > random(1)) vArr[paintArrPtr] += .3 + random(.5) // 80% chance that every other pixel is bright (but all are still random)\n    hArr[paintArrPtr] = fixH(paintHue)\n  }\n}\nvar newPainter = () => paintFizzle(1)\n\nfunction fizzleGrains(d) {\n  decay(clamp(1 / (volume + .1), .1, 10), d) // If low volume, decay slower\n  \n  beatDetected = newPainter\n  // Select parameters for other sound that will build a fizzle started by a bass note\n  if (claps > 1.5 * clapsEMA) paintFizzle()\n  // if (hh > 2 * hhEMA) paintFizzle()\n  // if (localVolRatio > 1.3 || volume > .7) paintFizzle()\n\n  renderer = (i, x, y, z) => { \n    var shimmer = .7 + .3 * wave(i / 6 + time(0.1 / 65.536)) \n    hsv(hArr[i], vArr[i] < .8, vArr[i] * vArr[i] * shimmer)\n  }\n}\n\n\n// Flash random segments faster and faster during a build\nvar segmentsOn, segmentCount, beatsRemaining, flash = 0\nfunction buildupSegments() {\n  beatsRemaining = currentPatternBeats - beatCount\n  segmentCount = pow(2, 5 - ceil(max(0, log2((beatsRemaining - 4))))) + 2\n  if (beatsRemaining < 4) { flash = note_16 > .8 || note_16 < .1 }\n  else if (beatsRemaining < 8) { flash = note_8 > .8 || note_8 < .1 }\n  else { flash = beat > .8 }\n  triggerOn(flash, () => {\n    segmentsOn = random(32768) \n    if (segmentCount <= 6) { // Ensure at least 1 segment is on\n      while (((segmentsOn << 16) & (pow(2, segmentCount) - 1)) == 0) { \n        segmentsOn = random(32768)\n      }\n    }\n  })\n\n  renderer = (index, x, y, z) => {\n    var segmentDec = segmentCount * index / pixelCount\n    var segmentNum = floor(segmentDec)\n    var spacer = index % (pixelCount / segmentCount) > 1\n    var v = ((segmentsOn >> segmentNum) & (flash >> 16) ) << 16\n    var h = .2 + phrasePct + triangle(segmentDec % 1) / 8\n    hsv(h, beatsRemaining >= 2, v * spacer) // White last 2 beats\n  }\n}\n  \n\n// 80s ish thing. Flashing photosensitivity warning. \nfunction hyper(delta) {\n  renderer = (index, x, y, z) => {\n    var sat = 1\n    var pct = index / pixelCount\n    if (beatCount > 18) pct = 1 - pct\n    var sweepIn = pct - clamp((4 - beatCount) / 4, 0, 1) + max(0, 1 - abs(beatCount - 16) / 2)\n    var pulse = 8 * sweepIn * sweepIn * (.5 + sweepIn) + beat * (sweepIn > 0)\n    \n    if (pulse > 1) { // Modulate the furthest ones blinking to loudness\n      pulse = pulse % 1 * (1 - pct * pct * (note_16 * (localVolRatio - .8) % 1 > .25))\n    } else { // White flashes for first pulse\n      sat = note_16 > .5\n    }\n    hsv(floor(beatCount / 8) * .166 -.166 * (beatCount > 18), sat, pulse)\n  }\n}\n\n\n// Parrallax: A world of particles at varios distances\n//   Diagram: https://take.ms/iy5bJ\n{\nvar plxParticleCount = 20\nvar plxParticleOffsets = array(plxParticleCount)\nplxParticleOffsets.mutate(() => random(1))\nvar plxFocalLen = pixelCount * 6\nvar plxObjecMaxD = pixelCount * 10\nvar plxObjectMaxH = pixelCount / plxFocalLen * plxObjecMaxD\nvar plxWindowDepth = 1.5 * plxFocalLen\n}\nfunction parallax(delta) {\n  var t1 = phrasePct // Base position before indivdual offsets\n  // Introduct the back-and-forth motion\n  if (currentPatternPct > .5) t1 += wave(8 * phrasePct) / 8 * 2 * (currentPatternPct - .5)\n  decay(.2, delta)\n\n  for (i = 0; i < plxParticleCount; i++) {\n    var particleX = plxObjectMaxH * ((t1 + plxParticleOffsets[i]) % 1)\n    var distance = plxObjecMaxD - plxWindowDepth * i / plxParticleCount // plxObjecMaxD - plxWindowDepth * `nearness`\n    var projectedPosition = particleX / distance * plxFocalLen\n    var height = 3 * plxFocalLen / distance\n    var start = max(0, projectedPosition)\n    var end = min(pixelCount - 1, projectedPosition + height)\n    var hue = phrasePct + .63 - i / plxParticleCount / 5\n    for (index = start; index < end; index++) {\n      hArr[index] = hue\n      sArr[index] = sqrt(1 - (index - start) / (end-start))\n      vArr[index] = .9\n    }\n  }\n  \n  renderer = (i, x, y, z) => { hsv(hArr[i], sArr[i], vArr[i]) }\n}\n\n\n// Raindrops splashing on the ground in front of you\n{\nvar dropCount = 4\nvar dropsX = array(dropCount)        // Current position of each drop, in pixels from index 0\nvar dropsNearness = array(dropCount) // 0 for 80m away, 1 for drops right next to the viewer\nvar dropsGroundX = array(dropCount)  // Cached position where the drop will splash on the ground, in pixels from index 0\nvar dropSplashes = array(pixelCount) // Blue pixels for the splashes \nvar splashH = (t, p) => max(0, 4 * t * (sqrt(p) / p - t)) // Splash height as a fn(time, parameter) - https://www.desmos.com/calculator/iwurasjyu9\n}\nfunction newDrop(close) {\n  for (i = 0; i < dropCount; i++) {\n    if (dropsX[i] == 0) { \n      dropsX[i] = 1\n      dropsNearness[i] = 1 - random(1) / (1 + close * 3)\n      // Given a nearness, return X, the pixel index where a drop hits the ground and splashes. This ratio assumes the strip\n      // is a 24mm tall image plane, 50mm focal length, drops are randomly distributed between right next to you and 80m away\n      dropsGroundX[i] = pixelCount / 2 + pixelCount / 19.2 / (1 - dropsNearness[i])\n      break\n    }\n  }\n}\nfunction newDropClose() { newDrop(1) }\n\nfunction rain(delta) {\n  if (!setupDone) { \n    dropSplashes.mutate(() => 0)\n    dropsX.mutate(() => 0)\n    setupDone = 1\n  }\n  \n  if (SB()) { // Sensor board: New raindrops on beatDetected()\n    beatDetected = newDropClose\n    clapsDetected = newDrop\n\n    if (beatIntervalTimer / 1000 > 8 * SPB) { // If 8 beats of silence passed, rain randomly\n      if (random(800) < delta) newDrop() \n    }\n  } else { if (random(400) < delta) newDrop() }\n  \n  for (i = 0; i < dropCount; i++) {\n    if (dropsX[i] > 0) { // Drop is active\n      if (dropsX[i] >= 1.3 * pixelCount) { dropsX[i] = 0; continue } // Recycle a drop because it's well past the image plane\n      var pastGround = dropsX[i] - dropsGroundX[i]\n      if (pastGround > 0) {\n        splashAnimPct = pastGround / (pixelCount / 4)\n        dropsX[i] += delta / 24 // Speed for splash animation doesn't depend on nearness\n        if (splashAnimPct >= .9) { dropsX[i] = 0; continue } // Recycle drop when done splashing\n        for (n = 0; n <= 3; n++) { // Compute X for each of 4 splashing pixels \n          splashPixel = clamp(dropsGroundX[i] - dropsNearness[i] * 20 * splashH(splashAnimPct, sqrt(pow(2, n))), 0, pixelCount - 1)\n          dropSplashes[splashPixel] = dropsNearness[i] * dropsNearness[i] * (1 - splashAnimPct)\n        }\n      } else {\n        // Drop is still falling. Near drops appear to be falling faster through the image plane.\n        dropsX[i] += delta * (.1 + .4 * dropsNearness[i])\n      }\n    }\n  }\n\n  renderer = (index, x, y, z) => {\n    index = pixelCount - 1 - index\n    if (index < pixelCount / 2) { // Top half of strip is cloudy sky\n      var skyV = .05 + .1 * index / pixelCount\n      hsv(.05, 0.7, skyV * skyV)\n    }\n    var maxV = 0 // Since closer drops are brighter, this layers overlapping drops properly\n    for (i = 0; i < dropCount; i++) {\n      if ( index < dropsX[i] // Skips inactive drops where dropsX[i] == 0\n        && index > (dropsX[i] - 20 * dropsNearness[i]) // The tail is 0-20 pixels following dropX \n        && index < dropsGroundX[i] ) // Part above the ground\n          maxV = max(maxV, .2 + .8 * dropsNearness[i])\n    }\n    if (maxV > 0) hsv(0, 0, maxV * maxV) // White falling drips\n    if (dropSplashes[index]) { // Blue splashes\n      hsv(.55, .8, dropSplashes[index])\n      dropSplashes[index] = 0\n    }\n  }\n}\n\n\n// Flashes patches of _W_W_W_ and _RB_RB_RB_\nfunction fillRB(x, l) {\n  for (i = x; i < x + l; i++) {\n    hArr[i] = .66 * (i % 3 == 0)\n    sArr[i] = 1\n    vArr[i] = i % 3 != 1\n  }\n}\nfunction fillDots(x, l) {\n  for (i = x; i < x + l; i++) { vArr[i] = i % 2 == 1; sArr[i] = !vArr[i] }\n}\nfunction fillBlue(x) { hArr[x] = .5; vArr[x] = random(.3) }\nfunction flashSieves(delta) {\n  decay(localVolRatio ? 1 : 9, delta)\n  length = floor(random(.2 * pixelCount))\n  start = floor(random(pixelCount - length))\n  if (localVolRatio > 2 ) fillRB(start, length)\n  if (localVolRatio > 1.3 && random(10) < 1) fillDots(start, length) \n  if (localVolRatio == 0 && random(20) < 1) fillBlue(floor(time(.001) * pixelCount)) \n  renderer = (i, x, y, z) => { hsv(hArr[i], sArr[i], vArr[i]) }\n}\n\n\n// Detect notes, plot piano. Try with a flute solo. See freq limits on detectNote().\nvar fade, pixPerNote\nfunction piano(delta) {\n  if (!SB()) next() // Pattern is trivial without SB\n  fade = min(beatCount / 4, min(1, (currentPatternBeats - beatCount) / 4)) // Fade in and out\n  fade *= fade\n  var pianoNotes = 3 * 12; pixPerNote = pixelCount / pianoNotes\n  noteNum = mod(detectNote() - 12, pianoNotes) // Accurate for noteNums > 14; plots all noteNums with rollover\n  if (maxFrequencyMagnitude < .05) noteNum = -1 // Threshold seems to work for mic and line in\n  decay(.2, delta)\n  \n  renderer = (i, x, y, z) => {\n    var note = i / pixPerNote\n    var isNatural =  (0b010110101101 >> (floor(note) % 12)) & 1\n    hsv(.06, .7, isNatural * (.02 + .1 * (clapsOn || hhOn)) * fade) // Black accidentals, dim naturals\n    if (!floor(i % pixPerNote)) hsv(.05, .7, (.2 + bassFastEMA / maxBass) * fade) // Piano key dividers\n    if (note > noteNum && note < noteNum + 1) { // Detected note\n      hArr[i] = fixH(noteNum / 12)\n      vArr[i] = .1  + 3 * maxFrequencyMagnitude\n    }\n    if (vArr[i] > .02) hsv(hArr[i], 1, vArr[i] * fade) // Render detected note\n  }\n}\n \n\n// Low budget Pacifica - not actually sound reactive\nvar ptrBase, t1, t2, fade, hueDrift\nfunction prifika(delta) {\n  fade = min(beatCount / 4, 1); fade *= fade\n  hueDrift = max(0, (beatCount - 16) / 64)\n  ptrBase += delta >> 12 // Provides additional offset panning for one of the waves\n  t1 = time(.1)\n  t2 = triangle(pow((currentPatternS + 7.7) / 15.0733 % 1, 7)) // White pulse, sync'd to arbitrary demo\n  renderer = (i, x, y, z) => {\n    var pct = i / pixelCount\n    var s = wave(10 * (pct/8 - t2)) * square(pct/8 - t2 + .125, .1)\n    s *= s*s // White pulse\n    pct = 2 * (pct - .5) // Scale\n    var w1 = .5 * wave(2 * pct + t1 + ptrBase) - .03\n    var w2 = .5 * wave(2.3 * pct - t1) - .03\n    var w3 = wave(1.7 * pct - t1 - .25)\n    var w4 = wave((1 + 3 * wave((t1 / 2 - 1)* t1)) * pct + 2 * t1 - .25)\n    var w5 =  wave(1.1 * pct - t1 - .25 - ptrBase/2.3) / 2 - .25\n    var v = w1 + w2 + w4/2 + s + w5\n    \n    hsv(themeHue + hueDrift + .1 * w3 - .1 * w4, sqrt(1-s), v * v * v * fade * volume)\n  }\n}\n\n\n// Gradients that posterize quickly into segments\n// Creates segments by detecting zero-crossings in this: https://www.desmos.com/calculator/9z8twmylka\nfunction gapGen(x, p) { return (wave(x/5/p)*wave(x/2) + wave(x/3/p)*wave(x/7)) / 2 - .25 }\nfunction fillHue(l, r, h) { for (i = l; i < r; i++) hArr[i] = h }\nvar posterize = 0\nfunction togglePosterize() { posterize = !posterize }\nfunction flashPosterize() {\n  beatDetected = togglePosterize\n  gapParam = 1 + .4 * triangle(phrasePct) // This animates the posterized segments lengths\n  FPLastSign = -1 // Init value. Will be 0 for gapGen(x) <= 0, 1 for positive gapGen(x)\n  FPSegmentStart = 0\n  FPHFn = (pct) => .3 + pct + time(5 / 65.536) // Hue function for gradient\n  \n  renderer = (i, x, y, z) => {\n    pct = i / pixelCount\n\n    if (posterize) {\n      hsv(hArr[i], 1, (hArr[i] == hArr[max(0, i - 1)]))\n    } else {\n      hsv(FPHFn(pct), .75, .7)\n    }\n\n    // Calculate posterized segments for next frame\n    var f = gapGen(5 + 10 * pct, gapParam) // Animate pct's coeffecient to vary segment frequency\n    if (FPLastSign != f > 0) { // Detect a zero crossing in the gap function\n      fillHue(FPSegmentStart, i, FPHFn((FPSegmentStart + i) / 2 / pixelCount))\n      FPSegmentStart = i\n    }\n    FPLastSign = f > 0\n  }\n} \n\n\nfunction splotchOnBeatDetected(highs) {\n  SOBColor = highs ? .5 : .97 + random(.06)\n  SOBWidth = .05 + random(.2) // halfWidth in pct of strip\n  SOBPos = SOBWidth + random(1 - 2 * SOBWidth)\n  SOBLife = 1\n}\nfunction splotchOnBeat(delta) {\n  beatDetected = splotchOnBeatDetected\n  SOBLife *= .98\n  renderer = (index, x, y, z) => {\n    pct = index / pixelCount\n    hsv(SOBColor, 1, near(pct, SOBPos, SOBWidth) * SOBLife * SOBLife)\n    if (index % 3 == 0) {\n      if (hhOn && pct > .8) hsv(.05, .8, 1)\n      if (clapsOn && pct < .2) hsv(.05, 1, 1)\n    }\n  }\n}\n\n\n// A spectrum analyzer with some oscillating parameters\n// Good demo: Sober by Childish Gambino, around 2:30\nvar fBins = 20, pixPerBin = pixelCount / fBins // bins must be <= 32 (# freq bins of SB)\nvar frequencyEMAs = array(fBins + 1)\nvar maxFreqEA = 0, scaledmaxFreqEMA\nfunction analyzer(delta) {\n  if (!SB()) next() // Pattern is trivial without SB\n  fade = min(1, beatCount / 8); fade *= fade\n  targetFill = volume / 2\n  decay(.1)\n  sensitivity = calcPIController(pic, targetFill - brightnessFeedback / pixelCount)\n  brightnessFeedback = 0\n  \n  hSmoothingOsc = wave(2 * phrasePct + .5)     // Color splay oscillation\n  vSmoothingOsc = wave(2 * phrasePct) // Oscillate beteen brightness smoothing on running average or statistical pick\n  runAvg = 0  //volume // Base running average = base brightness.\n  \n  for (i = 0; i < fBins + 1; i++) {\n    frequencyEMAs[i] = .2 * (frequencyData[i] * 10) + .8 * frequencyEMAs[i]\n  }\n  \n  for (i = 0; i < pixelCount; i++) { // Calculate each pixel\n    bin = floor(i / pixelCount * fBins) // Up to 32 bins\n    vArr[i] = max(vArr[i], sensitivity * frequencyEMAs[bin])\n    targetH = clamp(frequencyData[bin] * 7 / frequencyEMAs[bin], 1, 2.5) / 2\n    if (targetH - hArr[i] > .2) hArr[i] = targetH // Jump to sudden peaks per bin\n    hArr[i] += (targetH - hArr[i]) * .03          // Fade peak hue back slowly\n  }\n\n  if (currentPatternPct > .5) { // Peak Freq white\n    maxFreqEA = .95 * maxFreqEA + .05 * log2(maxFrequency)\n    scaledmaxFreqEMA = pow(2, maxFreqEA)\n  \n    for (i = 0; i < pixelCount; i++) {\n      sArr[i] += (1 - sArr[i]) / 2\n      nearness = near(scaledmaxFreqEMA / 1000, i / pixelCount, .05)\n      if (nearness > 0) {\n        sArr[i] = 1 - nearness\n        vArr[i] = max(0, vArr[i] + nearness - .8)\n      }\n    }\n  }\n  \n  renderer = (i, x, y, z) => {\n    var near_i = clamp(i + (random(pixPerBin) - pixPerBin / 2), 0, pixelCount - 1)\n    \n    var v = vArr[i]\n    brightnessFeedback += clamp(v, 0, 1)\n    \n    if (i < pixPerBin) { // Running average of bin neighbors\n      runAvg += v\n      v = runAvg / (i + 1)\n    } else { \n      runAvg = runAvg + v - vArr[i - pixPerBin]\n      v = runAvg / pixPerBin\n    }\n\n    v = vSmoothingOsc * v + (1 - vSmoothingOsc) * vArr[near_i]\n    h = hSmoothingOsc * hArr[i] + (1 - hSmoothingOsc) * hArr[near_i]\n    \n    hsv(h, sArr[i], v * fade)\n  }\n}\n\n\n// Elastic: Particles connected by rubber bands. Looks best with music that doesn't have beats every quarter note.\n{\nvar particleCount = 5\nvar particlesX = array(particleCount)\nvar particlesV = array(particleCount)\nvar tensions = array(particleCount)\nvar unstretchedLen = pixelCount / 3 / particleCount\nvar elasticTarget = particlesX[0] = .5\n}\n// Move at least 1/8 of strip in either direction\nvar elasticOnBeat = () => elasticTarget = (elasticTarget/pixelCount + .125 + random(.75)) % 1 * pixelCount\nfunction elastic(delta) {\n  if (SB()) { // Sensor board: Move first ball on the beatDetected()\n    beatDetected = elasticOnBeat\n    if (beatIntervalTimer / 1000 > 4 * SPB) { // If 4 beats silence passed, wander around center\n      elasticTarget += (.5 - elasticTarget / pixelCount) + .7 * wave(time(.2) - .5)\n    }\n  } else { triggerOn(beat, elasticOnBeat) }\n  \n  particlesX[0] += .2 * (elasticTarget - particlesX[0]) // Seek head to new location\n  decay(.001 + pow(triangle(beatCount / 32), 6)) // Leave trails at 16 beats in, 48 in, etc\n  colorSplay = volume  // How much to spread out colors\n  var springK = .1 + .4 * currentPatternPct   // Spring constant. Higher is more energetic.\n  var friction = .995 - springK/100   // Raise to .999 for lower spring constants / calmer songs\n  delta /= 60          // Scale time\n\n  for (var i = 0; i < particleCount - 1; i++) { // Calculate tensions for each pair\n    var dir = particlesX[i+1] - particlesX[i] > 0 ? 1 : -1\n    var dist = min(abs(particlesX[i+1] - particlesX[i]), pixelCount/2)\n    var stretch = (dist < unstretchedLen) ? 0 : dir * (dist - unstretchedLen)\n    tensions[i] = -springK * stretch // Force between i and i+1, in direction of action on particle i\n  }\n  for (var i = 1; i < particleCount; i++) { // Accellerate each particle\n    particlesV[i] += (tensions[i-1] - tensions[i]) * delta // dv = netF * dt. tension[particleCount] is 0\n    particlesV[i] *= friction\n    particlesX[i] += particlesV[i] * delta\n  }\n  for (var i = 0; i < particleCount; i++) { // Plot each particle\n    if (particlesX[i] > 0 && particlesX[i] < pixelCount ) {\n      var pctNext = frac(particlesX[i])\n      vArr[particlesX[i]] = 1 - pctNext \n      vArr[particlesX[i] + 1] = pctNext\n      hArr[particlesX[i]] = hArr[particlesX[i] + 1] = .85 - (colorSplay * colorSplay) * i / particleCount\n    }\n  }\n  \n  renderer = (index, x, y, z) => { hsv(hArr[index], 1, vArr[index]) }\n}\n\n\n// Rays of different frequency bands traversing the strip\nvar ptrBase, bassArrPtr, midsArrPtr, highsArrPtr\nvar bassArr = array(pixelCount), midsArr = array(pixelCount), highsArr = array(pixelCount)\nfunction soundRays(delta) {\n  if (!SB()) next() // Pattern is trivial without SB\n  \n  if (!setupDone) {\n    vArr.mutate(() => 0)\n    bassArr.mutate(() => 0)\n    midsArr.mutate(() => 0)\n    highsArr.mutate(() => 0)\n    setupDone = 1\n  }\n  \n  ptrBase += delta / 60 // Different speeds for different frequencies\n  highsArrPtr = mod(ptrBase * 7, pixelCount)\n  midsArrPtr = mod(ptrBase * 3.5, pixelCount) \n  bassArrPtr = mod(ptrBase * 2, pixelCount)\n\n  highsArr[mod(highsArrPtr - 1, pixelCount)] = clamp(hh / hhEMA - 1.5, 0, 1)\n  midsArr[mod(midsArrPtr - 1, pixelCount)] = clamp(claps / clapsEMA - 1.5, 0, 1)\n  bassArr[mod(bassArrPtr - 1, pixelCount)] = \n    // Different bass lines may require choosing between these and tuning them\n    clamp(bassFastEMA / maxBass * 1.5 - .5, 0, 1)\n    //clamp(bassFastEMA / bassSlowEMA * 1 - 1, 0, 1)\n  \n  \n  renderer = (i) => { \n    bass_i = (i + bassArrPtr) % pixelCount\n    mids_i = (i + midsArrPtr) % pixelCount\n    highs_i = (i + highsArrPtr) % pixelCount\n    \n    if (1) { // 240 vs 96 FPS\n      rgb(bassArr[bass_i] + .8 * midsArr[mids_i] + .19 * highsArr[highs_i] , \n          .2 * midsArr[mids_i],\n          .9 * highsArr[highs_i])\n    } else { // Use this if slower is OK but you need hue-wheel based manipulations\n      mixHV(0, bassArr[bass_i], .11, midsArr[mids_i])\n      mixHV(mixedH, mixedV, .86, highsArr[highs_i])\n      hsv(mixedH, 1, mixedV * mixedV)\n    }\n  }\n}\n\n\n// PATTERNS FOR TUNING SOUND DETECTION\n\nfunction renderInstrumentDetectors(index) {\n  var pct = index / pixelCount\n  if (index % 2 == 0) {\n    if (bassOn && pct < .1) hsv(.005, 1, .1) // Red on beat present\n    if (clapsOn && pct > .44 && pct < .55) hsv(.15, 1, .1) // Yellow claps\n    if (hhOn && pct > .9) hsv(0, 0, .1) // White high hats\n  } else {\n    if (debounceTimers[beatTimerIdx] > 0 && pct < .1) hsv(.0, 1, 1)   // Bright red during beat detected threshold\n    if (debounceTimers[clapsTimerIdx] > 0 && pct > .45 && pct < .55) hsv(.18, 1, 1) // Bright yellow during claps detected threshold\n    if ( // hh > 1.5 * hhEMA  &&\n        debounceTimers[hhTimerIdx] > 0\n        && pct > .9) hsv(.0, 0, 1)     // Bright white during high hat detected threshold  \n  }\n}\n\n\nfunction visualizeBassBands(delta) {\n  if (!SB()) next() // Pattern is trivial without SB\n  renderer = (index, x, y, z) => {\n    var bands = 5\n    var pct = index / pixelCount\n    var bin = floor(0 + pct * bands)\n    var pctOfBin = pct * bands % 1\n    var v = (frequencyData[bin] / bassSlowEMA / 2) > pctOfBin\n    hsv(1 - .01 * pctOfBin, 1, v)\n    if (abs(pixelCount * (bass / bassSlowEMA / 3) - index) < 2) hsv(.33, 1, 1)\n  }\n}\n\n\nfunction visualizeClapsBands(delta) {\n  if (!SB()) next() // Pattern is trivial without SB\n  renderer = (index, x, y, z) => {\n    var bands = 6\n    var pct = index / pixelCount\n    var bin = floor(18 + pct * bands) // Starts on 18\n    var pctOfBin = pct * bands % 1\n    var v = ((frequencyData[bin] << 4) / (clapsEMA/6) / 6) > pctOfBin\n    hsv(.5, 1, v * .3) // Cyan bins\n    renderInstrumentDetectors(index)\n  }\n}\n\n\nfunction visualizeHHBands(delta) {\n  if (!SB()) next() // Pattern is trivial without SB\n  renderer = (index, x, y, z) => {\n    var bands = 8\n    var pct = index / pixelCount\n    var bin = floor(24 + pct * bands)\n    var pctOfBin = pct * bands % 1\n    var v = ((frequencyData[bin] << 4) / (hhEMA/6) / 6) > pctOfBin\n    hsv(.36, .95, v * .3) // Mint bins\n    // if (bin == 29 || bin == 30) hsv(1, 1, v * .3) // Red for the ones this pattern uses to detect HH\n    renderInstrumentDetectors(index)\n  }\n}\n\n\nfunction visualizeVolumes(delta) {\n  if (!SB()) next() // Pattern is trivial without SB\n  renderer = (index, x, y, z) => {\n    pct = index / pixelCount\n    if (abs(pixelCount * (bassSlowEMA / maxBass) - index) < 4) hsv(.5, 1, .4) // Blue slow bass\n    if (abs(pixelCount * (bassFastEMA / maxBass) - index) < 2) hsv(.9, 1, 1)  // Purple fast bass\n    // if (abs(pixelCount * (bassVelocitiesAvg - .3) / .4 - index) < 2) hsv(.1, 1, 1) // Orange, lFA .3 to .7\n    if (abs(pixelCount * (3 + localVolRatio) / 6 - index) < 2) hsv(.36, .95, 1) // Green localVolRatio / 4\n    if (abs(pixelCount * volume - index) < 1.5) hsv(0, 0, 1) // White volume\n    renderInstrumentDetectors(index)\n  }\n}\n\n\n{\nvar selectedPattern\nexport function sliderChooseManualPattern (_v) { \n  selectedPattern = _v\n  beforeNext()\n}\nvar patterns = array(20)\npatterns[0] = piano\npatterns[1] = elastic\npatterns[2] = analyzer\npatterns[3] = flashPosterize\npatterns[4] = splotchOnBeat\npatterns[5] = soundRays\npatterns[6] = rain\npatterns[7] = parallax\npatterns[8] = hyper\npatterns[9] = buildupSegments\npatterns[10] = fizzleGrains\npatterns[11] = flashSieves\npatterns[12] = strobe\npatterns[13] = dancingPixel\npatterns[14] = halfSurge\npatterns[15] = bassScope\npatterns[16] = visualizeBassBands\npatterns[17] = visualizeClapsBands\npatterns[18] = visualizeHHBands\npatterns[19] = visualizeVolumes\n}\nfunction manualPattern(delta) {\n  patterns[selectedPattern * 19](delta)\n}\n\n// q(manualPattern, 16)  // This is very handy for debugging a particular pattern selected with the slider\n// q(manualPattern, 16)\n// q(manualPattern, 32)\n// q(manualPattern, 256)\n\n\n\n\n\n\n\n\n\n// ************************************************************************\n// * PROGRAM SEQUENCE - A series of calls to enqueue()                    *\n// ************************************************************************\n\n\nsetBPM(120)\nsetBeatsPerPhrase(16)        // Default is 32 beats per phrase\nplayUntilLoud(off, BPM * 3)  // Wait up to 3 minutes for sound\nenqueue(piano, 20)           // Enqueue 20 beats of the \"piano\" pattern\n \nexpectBass(.3)               // This helps detect initial beats better when\n                             // there's no history of bass levels\n\nexec(() => themeHue = .6)    // Set theme hue global variable to light blue\n\nplayUntilBeat(prifika, BPM)  // Play \"prifika\" pattern for up to a minute, \n                             // waiting for for a beat\n \nq(fizzleGrains, 8)           // On beat, switch to \"fizzleGrains\" for\n                             // 8 beats. Notice BPMEst in watcher.\n\nsetBPMToDetected()           // Update the BPM to the detected BPM if \n                             // 8 consistent beats were found\n\nq(soundRays, 8)              // `q()` is an alias for `enqueue()`\nq(buildupSegments)\nq(soundRays, 8)\nq(visualizeClapsBands, 2)\nq(visualizeHHBands, 2)\nq(visualizeBassBands, 2)\nq(visualizeVolumes, 2)\nq(hyper, 24)\nq(halfSurge)                // Without a duration, pattern plays for 1 phrase\nq(fizzleGrains, 8)\n\nexec(() => themeHue = .7)   // Set theme hue to darker blue / purple\nq(prifika, 34)\n\n// Music fades out\nexec(() => themeHue = .006) // Set theme hue to red\nplayUntilBeat(off, BPM * 3) // Wait for downbeat\n\nq(progress, 2)\nfor (i = 0; i < 2; i++) {\n  exec(() => direction ^= 1)\n  q(progress, 1)\n}\nfor (i = 0; i < 2; i++) {\n  exec(() => direction ^= 1)\n  q(sweep, 1)\n}\nq(quarters, 2)\nq(eiths, 4) \nfor (i = 0; i < 8; i++) { \n  exec(() => direction ^= 1)\n  exec(() => themeHue -= .002)\n  enqueue(sweep, .5)\n}\n\nq(halfnoteBassHit, 2)\nq(off, 2)\nq(visualizeBassBands, 4)\nq(halfnoteBassHit, 2)\nq(off, 2)\nq(visualizeBassBands, 2)\nq(off, 1.5)\nq(strobe, .5)\n\nexec(() => themeHue = .33)    // Dancing pixel starts green\nq(dancingPixel, 15.5)\nplayUntilBeat(off, 1)         // Realign with beat\n\nq(bassScope)\nq(elastic)\nq(splotchOnBeat)\n\nq(rain, 24)\nq(flashPosterize, 24)\nq(elastic, 16)\nq(parallax, 32)\nq(flashSieves, 16)\n\nq(analyzer, 64)\n\nbegin()                       // Every sequence must end with `begin()` :)\n\n"
  },
  "preview": "/9j/4AAQSkZJRgABAQAAAQABAAD/4gIoSUNDX1BST0ZJTEUAAQEAAAIYAAAAAAQwAABtbnRyUkdCIFhZWiAAAAAAAAAAAAAAAABhY3NwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAQAA9tYAAQAAAADTLQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAlkZXNjAAAA8AAAAHRyWFlaAAABZAAAABRnWFlaAAABeAAAABRiWFlaAAABjAAAABRyVFJDAAABoAAAAChnVFJDAAABoAAAAChiVFJDAAABoAAAACh3dHB0AAAByAAAABRjcHJ0AAAB3AAAADxtbHVjAAAAAAAAAAEAAAAMZW5VUwAAAFgAAAAcAHMAUgBHAEIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAFhZWiAAAAAAAABvogAAOPUAAAOQWFlaIAAAAAAAAGKZAAC3hQAAGNpYWVogAAAAAAAAJKAAAA+EAAC2z3BhcmEAAAAAAAQAAAACZmYAAPKnAAANWQAAE9AAAApbAAAAAAAAAABYWVogAAAAAAAA9tYAAQAAAADTLW1sdWMAAAAAAAAAAQAAAAxlblVTAAAAIAAAABwARwBvAG8AZwBsAGUAIABJAG4AYwAuACAAMgAwADEANv/bAEMAAwICAwICAwMDAwQDAwQFCAUFBAQFCgcHBggMCgwMCwoLCw0OEhANDhEOCwsQFhARExQVFRUMDxcYFhQYEhQVFP/bAEMBAwQEBQQFCQUFCRQNCw0UFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFP/AABEIAJYAZAMBIgACEQEDEQH/xAAVAAEBAAAAAAAAAAAAAAAAAAAACf/EABQQAQAAAAAAAAAAAAAAAAAAAAD/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/8QAFBEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEQMRAD8AlUAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD//2Q=="
}